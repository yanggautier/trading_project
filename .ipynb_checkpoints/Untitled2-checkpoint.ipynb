{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense,LSTM,Dropout\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    self.symbol = 'AAPL'  #股票代码\n",
    "    #设置用于训练和回测的开始/结束日期\n",
    "    start_date = '2005-01-01'  \n",
    "    end_date='2018-07-19'\n",
    "    field='close'\n",
    "    seq_len=100 #每个input的长度\n",
    "    prediction_len=20 #预测数据长度\n",
    "    train_proportion=0.8 #训练数据占总数据量的比值，其余为测试数据\n",
    "    normalise=True #数据标准化\n",
    "    epochs  = 1 #LSTM神经网络迭代次数\n",
    "    batch=100 #整数，指定进行梯度下降时每个batch包含的样本数,训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步\n",
    "    validation_split=0.1 # 0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。\n",
    "    lr=0.001 #学习效率\n",
    "    \n",
    "    def history_data():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c075b375c0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> Loading data... '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_datetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_proportion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> Data Loaded. Compiling...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c075b375c0b3>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(instrument, start_date, end_date, field, seq_len, prediction_len, train_proportion, normalise)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 加载数据，数据变化，提取数据模块\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. LSTM策略主体\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM\n",
    "# from tensorflow.keras.layers import \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def load_data(symbol,start_date,end_date,field,seq_len,prediction_len,train_proportion,normalise=True):\n",
    "    # 加载数据，数据变化，提取数据模块\n",
    "    fields=[field,'amount']\n",
    "    data=D.history_data(symbol,start_date,end_date,fields)\n",
    "    data=data[data.amount>0]\n",
    "    datetime=list(data['date'])\n",
    "    data=list(data[field])\n",
    "    seq_len=seq_len+1  \n",
    "    result=[]\n",
    "    for index in range(len(data)-seq_len):\n",
    "        result.append(data[index:index+seq_len])\n",
    "        \n",
    "    if normalise:\n",
    "        norm_result=normalise_windows(result)\n",
    "    else:\n",
    "        norm_result=result\n",
    "        \n",
    "    result=np.array(result)\n",
    "    norm_result=np.array(norm_result)\n",
    "    \n",
    "    row=round(train_proportion*norm_result.shape[0])\n",
    "    \n",
    "    data_test=result[int(row):,:]\n",
    "    datetime=datetime[int(row):]\n",
    "\n",
    "    test_datetime=[]\n",
    "    for index in range(len(datetime)):\n",
    "        if index % prediction_len==0 and index+seq_len<len(datetime)-prediction_len:\n",
    "            test_datetime.append(datetime[index+seq_len])\n",
    "    \n",
    "    train=norm_result[:int(row),:]\n",
    "    np.random.shuffle(train)   #随机打乱训练样本\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = norm_result[int(row):, :-1]\n",
    "    y_test = norm_result[int(row):, -1]\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test, data_test, test_datetime]\n",
    "    \n",
    "def normalise_windows(window_data):\n",
    "    #数据规范化\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data\n",
    "\n",
    "def denormalise_windows(normdata,data,seq_len):\n",
    "    #数据反规范化\n",
    "    denormalised_data = []\n",
    "    wholelen=0\n",
    "    for i, rowdata in enumerate(normdata):\n",
    "        denormalise=list()\n",
    "        if isinstance(rowdata,float)|isinstance(rowdata,np.float32):\n",
    "            denormalise = [(rowdata+1)*float(data[wholelen][0])]\n",
    "            denormalised_data.append(denormalise)\n",
    "            wholelen=wholelen+1\n",
    "        else:       \n",
    "            for j in range(len(rowdata)):\n",
    "                denormalise.append((float(rowdata[j])+1)*float(data[wholelen][0]))\n",
    "                wholelen=wholelen+1\n",
    "            denormalised_data.append(denormalise)\n",
    "    return denormalised_data\n",
    "\n",
    "def build_model(layers):\n",
    "    # LSTM神经网络层\n",
    "    # 详细介绍请参考http://keras-cn.readthedocs.io/en/latest/\n",
    "    model = Sequential()  \n",
    "\n",
    "#     model.add(LSTM(input_dim=layers[0],output_dim=layers[1],return_sequences=True))\n",
    "    model.add(LSTM(layers[1],input_shape=(layers[1],layers[0]),return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(layers[1],return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    rms=optimizers.RMSprop(lr=conf.lr, rho=0.9, epsilon=1e-06)\n",
    "    model.compile(loss=\"mse\", optimizer=rms)\n",
    "    start = time.time()\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def predict_point_by_point(model, data):\n",
    "    #每次只预测1步长\n",
    "    predicted = model.predict(data)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "def predict_sequence_full(model, data, seq_len):\n",
    "    #根据训练模型和第一段用来预测的时间序列长度逐步预测整个时间序列\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [seq_len-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, seq_len, prediction_len):\n",
    "    #根据训练模型和每段用来预测的时间序列长度逐步预测prediction_len长度的序列\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [seq_len-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs\n",
    "\n",
    "def plot_results(predicted_data, true_data):\n",
    "    #做图函数，用于predict_point_by_point和predict_sequence_full\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data)\n",
    "    plt.legend()\n",
    "    figure=plt.gcf()\n",
    "    figure.set_size_inches(20,10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    #做图函数，用于predict_sequences_multiple\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data)    \n",
    "    plt.legend()\n",
    "    figure=plt.gcf()\n",
    "    figure.set_size_inches(20,10)\n",
    "    plt.show()\n",
    "\n",
    "#主程序\n",
    "global_start_time = time.time() \n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train,y_train,X_test,y_test,data_test,test_datetime=load_data(conf.instrument,conf.start_date,conf.end_date,conf.field,conf.seq_len,conf.prediction_len,conf.train_proportion,normalise=True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "print(X_train.shape)\n",
    "model = build_model([1, conf.seq_len, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=conf.batch,\n",
    "    nb_epoch=conf.epochs,\n",
    "    validation_split=conf.validation_split)\n",
    "\n",
    "\n",
    "predictions = predict_sequences_multiple(model, X_test, conf.seq_len, conf.prediction_len)\n",
    "# predictions = predict_sequence_full(model, X_test, conf.seq_len)\n",
    "# predictions = predict_point_by_point(model, X_test)  \n",
    "   \n",
    "if conf.normalise==True:   \n",
    "    predictions=denormalise_windows(predictions,data_test,conf.seq_len)\n",
    "    y_test=denormalise_windows(y_test,data_test,conf.seq_len)\n",
    "\n",
    "print('Training duration (s) : ', time.time() - global_start_time)\n",
    "plot_results_multiple(predictions, y_test, conf.prediction_len)\n",
    "# plot_results(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5eb54f544848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 策略基本参数\n",
    "# 3.回测\n",
    "# 目前回测结构主要针对predict_sequences_multiple的预测结果，并且股票最好没有停牌\n",
    "# 回测其他结果可自行修改handle_data\n",
    "def initialize(context):\n",
    "    # 系统已经设置了默认的交易手续费和滑点，要修改手续费可使用如下函数\n",
    "    context.set_commission(PerOrder(buy_cost=0.0003, sell_cost=0.0013, min_cost=5))\n",
    "    # 传入预测数据和真实数据\n",
    "    context.predictions=predictions\n",
    "    context.true_data=y_test\n",
    "    context.date_time=test_datetime\n",
    "    # 设置持仓比\n",
    "    context.percent = 0.7\n",
    "    # 设置持仓天数\n",
    "    context.hold_days=conf.prediction_len\n",
    "    # 传入起止时间\n",
    "    context.start_date=context.date_time[0].strftime('%Y-%m-%d')\n",
    "    context.end_date=context.date_time[-1].strftime('%Y-%m-%d')\n",
    "    # 结束时间预计至少比开始时间多gap点才进场\n",
    "    context.gap=0\n",
    "    context.dt = 0\n",
    "\n",
    "# 回测引擎：每日数据处理函数，每天执行一次\n",
    "def handle_data(context, data):\n",
    "    current_dt = data.current_dt.strftime('%Y-%m-%d') \n",
    "    \n",
    "    can_do=pd.Timestamp(current_dt) in context.date_time\n",
    "    if can_do:\n",
    "        context.dt = current_dt\n",
    "        \n",
    "    sid = context.symbol(conf.instrument)\n",
    "    cur_position = context.portfolio.positions[sid].amount    # 持仓\n",
    "\n",
    "    row=context.date_time.index(pd.Timestamp(context.dt))\n",
    "  \n",
    "    prediction=context.predictions[row]\n",
    "    # 满足开仓条件\n",
    "    if prediction[-1]-prediction[0]>=context.gap and cur_position == 0 and data.can_trade(sid):\n",
    "        context.order_target_percent(sid, 1)\n",
    "    elif prediction[-1]-prediction[0]<context.gap and cur_position > 0 and data.can_trade(sid):\n",
    "            context.order_target(sid, 0)\n",
    "\n",
    "# 调用回测引擎\n",
    "m8 = M.trade.v4(\n",
    "    instruments=DataSource().write_pickle(conf.instrument),\n",
    "    start_date=test_datetime[0].strftime('%Y-%m-%d'),\n",
    "    end_date=test_datetime[len(test_datetime)-1].strftime('%Y-%m-%d'),\n",
    "    initialize=initialize,\n",
    "    handle_data=handle_data,\n",
    "    volume_limit=0.025,\n",
    "    order_price_field_buy='open',       # 表示 开盘 时买入\n",
    "    order_price_field_sell='close',     # 表示 收盘 前卖出\n",
    "    capital_base=1000000, \n",
    "    auto_cancel_non_tradable_orders=True,\n",
    "    data_frequency='daily',\n",
    "    price_type='真实价格',\n",
    "    product_type='股票',\n",
    "    plot_charts=True,\n",
    "    backtest_only=False,\n",
    "    benchmark='000300.SHA', \n",
    "    # 通过 options 参数传递预测数据和参数给回测引擎\n",
    "    options={'predictions': predictions}\n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
